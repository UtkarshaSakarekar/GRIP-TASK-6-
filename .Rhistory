x=c(2001,2002,2003,2004)
y=c(1,2,3,4)
d=data.frame(x,y)
d
barplot(y,xlab = "year",ylab="students",main="strength",col="pink,"green","violet","red",names.arg=y)
barplot(y,xlab = "year",ylab="students",main="strength",col="pink",names.arg=y)
rmultinom(10,10,0.1,0.2,0.7)
rmultinom(10,10,(0.1,0.2,0.7))
rmultinom(10,size=10,prob=c(0.1,0.2,0.7))
s=rmultinom(10,10,prob=c(0.1,0.2,0.7))
s
dmultinom(3,5,prob=c(0.5,0.25,0.25))
dmultinom(5,3,prob=c(0.5,0.25,0.25))
dmultinom(5,size=3,prob=c(0.5,0.25,0.25),log=FALSE)
dmultinom(5,size=null,3,prob=c(0.5,0.25,0.25),log=FALSE)
1-(dlnorm(4.2,0,0,1,))
1-(dlnorm(4.2,meanlog=0,sdlog=1,log=False))
1-(dlnorm(4.2,meanlog=0,sdlog=1,log=T))
1-(dlnorm(4.2,0,meanlog=0,sdlog=1,log=T))
x=c(25,19,38,52,39,46,46,30,49,27,39,44,63,31,67,42)
length(x)
me=41
cat("H0:madian=41\n")
cat("H1:madian not=41\n")
x=c(25,19,38,52,39,46,46,30,49,27,39,44,63,31,67,42)
me=41
cat("H0:madian=41\n")
cat("H1:madian <41\n")
sp=length(x[x>me])
sn=length(x[x<me])
n=sp+sn
pv=pbinom(sp,n,0.5)
pv
sp
sn
n
q()
score before=c(38)
37
32
35
35
34
37
38
40
31
40
31
41
score before=c(38,37,32,35,35,34,37,38,40,31,40,31,41)
length(score before)
x=c(38,37,32,35,35,34,37,38,40,31,40,31,41)
length(x)
y=c(39,37,32,35,35,34,36,38,36,31,40,31,41)
length(y)
plot(x,y,xlab="Score Before",ylab="Score After",main="Scatter Diagram")
d=data.frame(x,y)
r=cor(d)
cat("Correlation coefficient=",r,"\n")
r
plot(x,y,xlab="Score Before",ylab="Score After",main="Scatter Diagram","l")
plot(x,y,xlab="Score Before",ylab="Score After",main="Scatter Diagram",pch=16)
q()
install.packages("ClusterR")
library(ClusterR)
install.packages("ClusterR")
library(ClusterR)
q()
install.packages("ClusterR")
library(ClusterR)
q()
data=read.csv("C:\\Users\\SAKAREKAR\\Desktop\\data.csv")
data(iris)
tr = sample(1:nrow(iris),0.6*nrow(iris))
train_d = iris[tr,]
test_d = iris[-tr,]
library(rpart)
library(rpart.plot)
model = rpart(Species~., train_d, method = "class")
Plotting the decision tree
rpart.plot(model,type = 4, extra = 108)
rpart.plot(model,type = 4, extra = 108)
rpart.plot(model,type = 4, extra = 108)
rpart.plot(model,type = 4, extra = 108)
R
rpart.plot(model,type = 4, extra = 108)
rpart.plot(model,type = 4, extra = 108)
rpart.plot(model,type = 4, extra = 108)
rpart.plot(model,type = 4, extra = 108)
rpart.plot(model,type = 4, extra = 108)
rpart.plot(model,type = 4, extra = 108)
q()
accuracy
accuracy
accuracy
data(iris)
tr = sample(1:nrow(iris),0.6*nrow(iris))
train_d = iris[tr,]
test_d = iris[-tr,]
library(rpart)
library(rpart.plot)
model = rpart(Species~., train_d, method = "class")
##Plotting the decision tree
rpart.plot(model,type = 4, extra = 108)
##Confusion matrix and Accuracy
pred_cl = predict(model, test_d, type = "class")
c_mat = table(test_d[,5],pred_cl)
c_mat
accuracy = (sum(diag(c_mat))/sum(rowSums(c_mat))) * 100
accuracy
q()
